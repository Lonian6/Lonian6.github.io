---
title:          "Exploring State-Space-Model Based Language Model in Music Generation"
date:           2025-07-09
selected:       true
pub:            "International Society for Music Information Retrieval, Late Breaking Demo"
pub_ab:         "ISMIR LBD"
pub_date:       "2025"
abstract: >-
    We investigates the potential of Mamba-based State Space Models (SSMs) as an efficient alternative to Transformers for text-to-music generation. By adopting a single-layer codebook representation and adapting the SiMBA architecture into a decoder, the proposed model achieves significantly faster convergence and produces outputs closer to the ground truth under limited-resource settings. The findings demonstrate that SSMs offer a promising path for developing efficient and expressive music language models that maintain high performance with lower computational overhead.
# cover: /assets/images/covers/cover_2026_Training-Efficient Text-to-Music Generation with State-Space Modeling.png
authors:
- Wei-Jaw Lee
- Fang-Chih Hsieh
- Xuanjun Chen
- Fang-Duo Tsai
- Yi-Hsuan Yang
links:
    Web: https://lonian6.github.io/web-exploring-ssm/
    Paper: https://arxiv.org/abs/2507.06674
    # Code: https://github.com/Lonian6/SSM-TTM
---